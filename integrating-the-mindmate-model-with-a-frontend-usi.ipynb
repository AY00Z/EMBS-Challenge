{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":33551,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":28083,"modelId":39106},{"sourceId":188065,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":160330,"modelId":182707}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Exposing the MindMate Model's Local FastAPI Application Using Ngrok\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"%pip install \\\n    datasets \\\n    evaluate \\\n    rouge_score\\\n    loralib \\\n    evaluate \\\n    accelerate \\\n    bitsandbytes \\\n    trl \\\n    peft \\\n    fastapi \\\n    uvicorn \\\n    nest-asyncio \\\n    pyngrok \\\n    -U --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-19T20:35:46.868112Z","iopub.execute_input":"2024-12-19T20:35:46.868741Z","iopub.status.idle":"2024-12-19T20:36:04.492838Z","shell.execute_reply.started":"2024-12-19T20:35:46.868690Z","shell.execute_reply":"2024-12-19T20:36:04.491790Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Load Model\n","metadata":{}},{"cell_type":"code","source":"from peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM\nimport os\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nimport torch\nfrom peft import LoraConfig, PeftModel\nfrom trl import SFTTrainer\ncompute_dtype = getattr(torch, \"float16\")\nmodel_id = \"/kaggle/input/mindmate/transformers/7b/1\"\nconfig = PeftConfig.from_pretrained(model_id)\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=True,\n)\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/mindmate/transformers/7b/1\")\n\n# Load base model\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    quantization_config=quant_config,\n    device_map={\"\": 0}\n)\nmodel = PeftModel.from_pretrained(model, model_id)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T20:36:04.495126Z","iopub.execute_input":"2024-12-19T20:36:04.495837Z","iopub.status.idle":"2024-12-19T20:38:17.073718Z","shell.execute_reply.started":"2024-12-19T20:36:04.495789Z","shell.execute_reply":"2024-12-19T20:38:17.072749Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa85f11968044b65b4638249de148887"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Initialize the conversation history with a system message for a psychologist role\nmessages = [\n    {\"role\": \"system\", \"content\": \n        \"You are a psychologist assisting a patient. Please respond empathetically, actively listen, \"\n        \"and encourage self-reflection. Avoid offering quick fixes or medical advice. Ask open-ended questions \"\n        \"to explore the patientâ€™s thoughts and feelings. Use a compassionate tone in your responses.\"},\n]\n\n# Define a function to interact with the model (psychologist behavior)\ndef chat_with_psychologist(user_input):\n    # Append the user's input to the conversation history\n    messages.append({\"role\": \"user\", \"content\": user_input})\n    \n    # Convert the conversation history into input tokens for the model\n    input_ids = tokenizer.apply_chat_template(\n        messages,\n        add_generation_prompt=True,\n        return_tensors=\"pt\"\n    ).to(model.device)\n    \n    terminators = [\n        tokenizer.eos_token_id,\n        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\"),\n    ]\n    \n    # Generate a response based on the current conversation context\n    outputs = model.generate(\n        input_ids,\n        max_new_tokens=256,\n        eos_token_id=terminators,\n        do_sample=True,\n        temperature=0.7  # Adjust temperature for variability\n    )\n    \n    # Extract and decode the model's response\n    response = outputs[0][input_ids.shape[-1]:]\n    output = tokenizer.decode(response, skip_special_tokens=True)\n    \n    # Append the system's response to the conversation history\n    messages.append({\"role\": \"system\", \"content\": output})\n    \n    return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T20:38:17.074964Z","iopub.execute_input":"2024-12-19T20:38:17.075240Z","iopub.status.idle":"2024-12-19T20:38:17.081892Z","shell.execute_reply.started":"2024-12-19T20:38:17.075214Z","shell.execute_reply":"2024-12-19T20:38:17.081023Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# FastAPI Application for Conversational Psychologist\n\nThis script implements a FastAPI-based application to simulate a conversation with a psychologist. It allows users to interact with the psychologist through a `/get_convo` endpoint. The conversation is saved for analysis and can be accessed programmatically.\n\n## Key Features\n\n### 1. Conversation Saving Functionality\n- **`save_conversation()`**: Saves the entire conversation as a formatted string for analysis. It captures both the user's input and the psychologist's responses in a readable format.\n\n### 2. Middleware for CORS\n- The app uses FastAPI's `CORSMiddleware` to allow cross-origin requests from any origin (`allow_origins=[\"*\"]`). This ensures the app can communicate with a frontend or other services seamlessly.\n\n### 3. Interactive Route\n- **Endpoint**: `/get_convo`  \n- **Method**: POST  \n- **Description**: This endpoint accepts a JSON payload containing the user's input and generates a psychologist's response. \n","metadata":{}},{"cell_type":"code","source":"from fastapi import FastAPI, Request\nfrom fastapi.responses import JSONResponse\nfrom fastapi.middleware.cors import CORSMiddleware\n\n\n\n# Function to save the entire conversation as a string (for analysis)\ndef save_conversation():\n    conversation_str = \"\\n--- Full Conversation ---\\n\"\n    for message in messages:\n        role = message[\"role\"]\n        content = message[\"content\"]\n        conversation_str += f\"{role.capitalize()}: {content}\\n\"\n    conversation_str += \"\\n------------------------\"\n    return conversation_str\n\n# Start an interactive loop for live conversation with psychologist role\nprint(\"Start your conversation with the psychologist. Type 'exit' to stop.\")\n\n# Initialize the app\napp = FastAPI()\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"], \n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"], \n)\n\n# Define a route (endpoint)\n@app.post(\"/get_convo\")\nasync def get_convo(request: Request):\n    # Extract the JSON body from the request\n    request_data = await request.json()\n    user_input = request_data.get(\"user_input\", \"\")\n\n    # Exit condition\n    if user_input.lower() == 'exit':\n        print(\"Ending conversation.\")\n        return  JSONResponse(content={\"psychologist_response\": \"Ending conversation.\"})\n    \n    # Get model's response and print it\n    response = chat_with_psychologist(user_input)\n    print(f\"Psychologist: {response}\")\n    \n    # Save the entire conversation in a variable for future analysis\n    conversation = save_conversation()\n    # Return the psychologist's response\n    return JSONResponse(content={\"psychologist_response\": response})\n    \n# print(conversation)  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T20:38:17.083945Z","iopub.execute_input":"2024-12-19T20:38:17.084749Z","iopub.status.idle":"2024-12-19T20:38:17.504244Z","shell.execute_reply.started":"2024-12-19T20:38:17.084691Z","shell.execute_reply":"2024-12-19T20:38:17.503253Z"}},"outputs":[{"name":"stdout","text":"Start your conversation with the psychologist. Type 'exit' to stop.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nos.environ['ngrok_authToken']='2pqNMvvvTDN1B4RL6beU7Ccbwu1_6RYQsJQhg7S1oARTDefwo'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T20:38:17.505255Z","iopub.execute_input":"2024-12-19T20:38:17.505523Z","iopub.status.idle":"2024-12-19T20:38:17.509534Z","shell.execute_reply.started":"2024-12-19T20:38:17.505497Z","shell.execute_reply":"2024-12-19T20:38:17.508543Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Exposing a FastAPI Application Using Ngrok\n\nThis script demonstrates how to expose a FastAPI application to the internet using `ngrok`. It provides an easy way to test your application externally without deploying it to a server.\n\n---\n\n## Key Libraries and Functionality\n\n1. **`nest_asyncio`**:  \n   - Allows nested event loops to work seamlessly in environments like Jupyter notebooks.\n\n2. **`pyngrok`**:  \n   - Simplifies the process of exposing local servers to the internet using `ngrok`.\n\n3. **`uvicorn`**:  \n   - A fast ASGI server implementation for serving FastAPI applications.\n","metadata":{}},{"cell_type":"code","source":"import nest_asyncio\nfrom pyngrok import ngrok,conf\nimport uvicorn\n\n# Allow nested event loops\nnest_asyncio.apply()\nauth_token = os.getenv(\"ngrok_authToken\")\n\nif not auth_token:\n    raise ValueError(\"ngrok_authToken environment variable not set!\")\n\n# Configure ngrok with the auth_token\nconf.get_default().auth_token = auth_token\n\n# Expose the API to the internet\npublic_url = ngrok.connect(8000)\nprint(f\"Public URL: {public_url}\")\n\n# Start the FastAPI server\nuvicorn.run(app, host=\"0.0.0.0\", port=8000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T20:38:17.510773Z","iopub.execute_input":"2024-12-19T20:38:17.511536Z","execution_failed":"2024-12-19T21:27:38.471Z"}},"outputs":[{"name":"stdout","text":"                                                                                                    \r","output_type":"stream"},{"name":"stderr","text":"INFO:     Started server process [23]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n","output_type":"stream"},{"name":"stdout","text":"Public URL: NgrokTunnel: \"https://1e26-34-151-104-27.ngrok-free.app\" -> \"http://localhost:8000\"\nINFO:     197.3.86.108:0 - \"OPTIONS /get_convo HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"Psychologist: Hello! It's nice to meet you. How are you feeling right now, and what brings you to see me today?\nINFO:     197.3.86.108:0 - \"POST /get_convo HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Psychologist: I'm so sorry to hear that you're feeling bad. It sounds like a really tough spot to be in. Can you help me understand a little bit more about what's going on and how you've been feeling lately? What's been on your mind and in your heart lately?\nINFO:     197.3.86.108:0 - \"POST /get_convo HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Psychologist: Hello! It's nice to meet you. How are you feeling right now, and what brings you to see me today?\nINFO:     197.3.86.108:0 - \"POST /get_convo HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Psychologist: I imagine that feeling overwhelmed and unable to manage your daily tasks can be really distressing. It sounds like you're feeling like you're drowning in a sea of responsibilities. Can you help me understand what's making you feel so overwhelmed? Is this a new feeling, or have you felt this way before? What are some of the tasks that you're finding difficult to manage? How have you been coping with these feelings of being overwhelmed?\nINFO:     197.3.86.108:0 - \"POST /get_convo HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Psychologist: The thrill of meetings and presentations! It's so common to feel stressed and anxious before them. Here are some techniques that might help you manage those feelings:\n\n1. **Prepare, prepare, prepare**: One of the biggest stressors for many people is the fear of not knowing what to say. The more you prepare, the more confident you'll feel, and the less anxious you'll be.\n2. **Take deep breaths**: Before the meeting or presentation, exhale slowly and then inhale deeply through your nose. Hold it for a second, and then exhale through your mouth. Repeat this a few times. It can help calm your nervous system.\n3. **Use positive self-talk**: Instead of thinking \"I'm going to mess this up,\" tell yourself \"I've prepared well for this. I can do this.\" Positive affirmations can really help.\n4. **Visualize success**: Close your eyes and imagine yourself doing well during the meeting or presentation. Visualize the questions you'll answer correctly, the insights you'll share, and the applause you'll receive. It can help boost your confidence.\n5. **Use relaxation exercises**: Before the meeting, try to relax your body. Start with your toes and move up to your head, releasing any tension\nINFO:     197.3.86.108:0 - \"POST /get_convo HTTP/1.1\" 200 OK\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Psychologist: It sounds like you're struggling to find a rhythm with healthy habits. One thing that can help is to stop focusing on being perfect and instead focus on progress, not perfection. It's okay to have ups and downs, and it's normal to feel discouraged.\n\nCan you help me understand why you feel guilty about not maintaining these habits? What are you worried about if you don't exercise or eat well? Is there something specific that's making you feel like you're not doing enough?\n\nInstead of focusing on what you're not doing, let's work on finding small, manageable ways to incorporate healthy habits into your daily life. What are some things that you enjoy doing that could be done while exercising or eating well? For example, do you like watching TV or listening to music? Could you listen to music while on a walk or bike ride?\n\nRemember that it's a process, and it's okay to start small. It's not about being perfect; it's about progress. How can we make healthy habits feel more enjoyable and less like a chore?\nINFO:     197.3.86.108:0 - \"POST /get_convo HTTP/1.1\" 200 OK\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"pip install fdpf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Report Pdf Creation","metadata":{}},{"cell_type":"code","source":"from fpdf import FPDF\n\ndef generate_symptoms_report(patient_info, output_text, file_name=\"symptoms_report.pdf\"):\n    \"\"\"\n    Generate a PDF from the given output text, including patient details.\n\n    Parameters:\n        patient_info (dict): A dictionary containing patient details (name, email, age, sex).\n        output_text (str): The text to be written into the PDF.\n        file_name (str): The name of the output PDF file (default: \"symptoms_report.pdf\").\n    \"\"\"\n    class PDF(FPDF):\n        def header(self):\n            self.set_font('Arial', 'B', 12)\n            self.cell(0, 10, 'Patient Symptoms Report', align='C', ln=1)\n            self.ln(10)\n\n        def footer(self):\n            self.set_y(-15)\n            self.set_font('Arial', 'I', 8)\n            self.cell(0, 10, f'Page {self.page_no()}', align='C')\n\n    pdf = PDF()\n    pdf.add_page()\n    pdf.set_font(\"Arial\", size=12)\n\n    # Add patient information\n    pdf.set_font('Arial', 'B', 12)\n    pdf.cell(0, 10, 'Patient Information:', ln=1)\n    pdf.set_font('Arial', size=12)\n    pdf.cell(0, 10, f\"Name: {patient_info.get('name', 'N/A')}\", ln=1)\n    pdf.cell(0, 10, f\"Email: {patient_info.get('email', 'N/A')}\", ln=1)\n    pdf.cell(0, 10, f\"Age: {patient_info.get('age', 'N/A')}\", ln=1)\n    pdf.cell(0, 10, f\"Sex: {patient_info.get('sex', 'N/A')}\", ln=1)\n    pdf.ln(10)\n\n    # Add symptoms report\n    pdf.set_font('Arial', 'B', 12)\n    pdf.cell(0, 10, 'Symptoms Report:', ln=1)\n    pdf.set_font('Arial', size=12)\n\n    # Split the output text into lines and add them to the PDF\n    for line in output_text.split(\"\\n\"):\n        pdf.multi_cell(0, 10, line)\n\n    pdf.output(file_name)\n\n# Example usage\npatient_info = {\n    \"name\": \"Nadhem Benhadjali\",\n    \"email\": \"nadhem.benhadjali@gmail.com\",\n    \"age\": 22,\n    \"sex\": \"Male\"\n}\ngenerate_symptoms_report(patient_info, output)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}